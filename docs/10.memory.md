# PCAI 系統架構說明：記憶與對話 (Memory & Session)

本文件說明 PCAI 系統中關於對話狀態管理 (Session) 與長期/短期記憶 (Memory) 的核心架構。

## 1. 對話狀態 (Session)

Session 負責儲存當前的對話上下文 (Context Window)，讓 Agent 能夠進行連續對話。

### 核心組件
- **結構定義**: `internal/history/session.go`
    - `Session` struct 包含 `ID` (字串), `Messages` (對話陣列), `LastUpdate` (時間戳)。
- **儲存位置**: `botmemory/history/*.json`
    - 每個 Session 存為一個 JSON 檔案。
    - CLI 模式預設讀取最新修改的 Session (`LoadLatestSession`)。
    - Telegram 模式為每個 User ID 建立獨立 Session (`telegram_{UserID}.json`)。

### 運作流程 (Telegram 範例)
1.  **用戶傳訊**: `AgentAdapter` 接收訊息。
2.  **載入/建立**: 呼叫 `history.LoadSession("telegram_" + userID)`。若無則建立新檔。
3.  **對話**: 將用戶訊息 append 到 `Messages`，送入 LLM。
4.  **回應**: 將 LLM 回應 append 到 `Messages`。
5.  **存檔**: 呼叫 `history.SaveSession()` 寫回 JSON。
6.  **歸納 (RAG)**: 背景執行 `history.CheckAndSummarize`，若對話過長或閒置過久，會觸發歸納機制（目前主要依賴時間或手動觸發）。

---

## 2. 記憶系統 (Memory)

記憶系統負責長期保存知識、事實與重要資訊，並支援語意搜尋 (Semantic Search)。

### 核心組件
1.  **Manager (`internal/memory/manager.go`)**:
    - **Vector Store**: 維護一個記憶條目 (`Entry`) 的列表。
    - **Embedding**: 使用 Ollama (`mxbai-embed-large`) 將文字轉為向量。
    - **Persistence**: 存於 `botmemory/knowledge/pcai_memory.sqlite` (包含向量與 FTS5 全文索引)。
    - **Search**: 支援 Cosine Similarity + 關鍵字加權混合搜尋。

2.  **Controller (`internal/memory/controller.go`)**:
    - **Router**: 負責協調記憶的寫入流程。
    - **Integration**: 整合 `Manager` (長期儲存) 與 `PendingStore` (待確認區)。

3.  **Pending Store (`internal/memory/pending_store.go`)**:
    - **Buffer**: 暫存 AI 提取的記憶，等待用戶確認。
    - **TTL**: 預設 24 小時過期。
    - **Confirmation**: 用戶透過 `memory_confirm` 工具批准後，才寫入 Manager。

4.  **Skills (`internal/memory/skills.go`)**:
    - **Extraction**: 定義如何從對話中提取記憶（雖程式碼有框架，目前主要依賴 LLM Tool Use 直接呼叫 `memory_save`）。

### 儲存位置
- **向量庫與索引**: `botmemory/knowledge/pcai_memory.sqlite`
  - **功能角色**：此為系統大腦的「**超級目錄與高速檢索庫（機器專用）**」。當 `MEMORY.md` 變更時，系統會自動在背景將文字切塊、加上 CJK 空白字元並算出向量存放於此。
  - **雙重引擎**：它同時包含 `chunks_fts` 虛擬資料表（提供毫秒級的 `BM25` 關鍵字全文檢索）與 `embeddings` 表（提供語意相似度的 `Vector Search` 檢索）。若此檔案遺失，系統會在重啟時依據 `MEMORY.md` 自動重建，故不需手動備份。
- **長期記憶日誌**: `botmemory/knowledge/MEMORY.md` (與 `memory/*.md`) (人類閱讀用，核心事實基準，容量無上限)
- **短期記憶 (SQLite)**: `pcai.db` -> table `short_term_memory` (用於晨間簡報、暫存對話摘要)。

### 運作流程 (記憶寫入)
1.  **觸發**: 用戶說 "記住我喜歡藍色"。
2.  **工具呼叫**: Agent 呼叫 `memory_save` 工具。
3.  **暫存**: 內容存入 `PendingStore`，回傳 Pending ID。
4.  **通知**: Agent 告知用戶 "已暫存，請確認"。
5.  **確認**: 用戶說 "確認" 或呼叫 `memory_confirm`。
6.  **寫入**: Controller 將內容移入 `Manager` (計算向量並存檔) 並追加到 `MEMORY.md`。

## 3. 記憶庫與 RAG (檢索增強生成) 機制

根據專案的架構設計，記憶庫（RAG）主要分為 **寫入時機** 與 **搜尋與使用時機** 兩個主要部分。本文件詳細說明這兩大部分的運作流程。

### 3.1 RAG 何時會被寫入？

記憶庫目前主要有三種寫入機制，其中最重要的機制改為**「先暫存後確認」**：

#### 1. AI 手動記憶（需要使用者確認）
- **關連檔案**：`docs/rag_write_confirmation.md`, `internal/memory/pending_store.go`, `tools/memory_save.go`
- **時機**：當你在對話中明確要求 AI 記住某些資訊（例如：「記住我喜歡喝咖啡」），AI 會呼叫 `memory_save` 工具。
- **寫入流程**：
  - 資料**不會立刻永久寫入**，而是進入 `PendingStore` 的未確認佇列（30 分鐘自動過期）。
  - AI 接著會反問你：「準備記住XXX，確認嗎？」
  - 只有當你回答「確認」時，AI 呼叫 `memory_confirm` 工具，才會正式寫入 `botmemory/knowledge/MEMORY.md`，並同步更新 SQLite 內的向量索引 (Vector DB)。

#### 2. 對話自動紀錄（每日日誌儲存）
- **關連檔案**：`internal/history/history.go` (函式 `CheckAndSummarize`)
- **時機**：每次你送出訊息時（當系統啟動 `GlobalMemoryToolKit` 時）。
- **寫入流程**：使用者的發言會被即時寫進今日專屬的日誌檔 `botmemory/memory/YYYY-MM-DD.md`。這些紀錄之後會被分塊（Chunking）與向量嵌入（Embedding）並索引到 SQLite 資料庫。

#### 3. 背景閒置歸納（舊版歷史濃縮備用機制）
- **關連檔案**：`internal/history/history.go` (函式 `CheckAndSummarize`)
- **時機**：當對話階段（Session）超時閒置逾 1 小時後自動觸發。
- **寫入流程**：系統會將這 1 小時內的對話重點提煉（精煉出3-5個關鍵字），儲存至長時間備份文件 `botmemory/history/auto_summaries.md`。

---

### 3.2 RAG 何時會用來搜尋/作為回答參考？

記憶檢索直接綁定在 **AI 回答生成前的攔截層**，分為**短期動態比對**與**長期向量搜尋**，讓它能不被察覺地自然提取背景知識：

#### 1. 提問前的動態搜尋注入 (自動 RAG Context)
- **關連檔案**：`internal/agent/memory_context.go` (函式 `BuildMemorySearchFunc`)
- **時機**：每次發送提問前，系統都會預先拿你的「問題字詞」作為 Query 去執行 RAG 搜索，然後**混入這次發給 LLM 的隱含 Prompt 中**。
  - **短期記憶快速比對**：若你的問題出現了特定關鍵字（如：`天氣`、`行事曆`、`信件`等），系統會直接從 SQLite 短期資料表抓近 3 筆對應資料。
  - **長期記憶混合過濾（向量 + 關鍵字 BM25）**：將使用者的問題拿去資料庫做關聯強度比對（Threshold 需超過 `0.05`），最多取回前 3 筆切塊的記憶文字。
    - **【容量無上限與 Context 限制說明】**：`MEMORY.md` 檔案本身的內容是**不限字數的（無限容量）**。當存入大量對話時，底層 SQLite 索引會將其切塊 (Chunking)。為避免過長的上下文導致 LLM 迷失重點 (Lost in the Middle) 或超過 Token 限制，系統在擷取「最關聯的 3 筆記憶」發送給 AI 時，**嚴格限制每筆記憶區塊最多擷取 1500 個中文字元 (Runes)**。這樣既能保存無盡過往，又能維持 AI 回答精準度。
- **注入結果**：一旦搜尋到高度關聯的背景知識，系統會將這段記憶預設為**「【最高優先級警告】這份背景代表實際的生活...你必須絕對無條件信任」**的嚴格前綴指令附加在 Prompt 開頭，確保 AI 根據你的真實背景回答。

#### 2. 全域提示詞附帶 (靜態 System Prompt)
- **關連檔案**：`internal/history/rag.go` (函式 `GetRAGEnhancedPrompt`)
- **時機**：如果系統有長遠的核心 Bootstrap 記憶，或是單純沒找到高度關聯片段時作為兜底（Fallback），系統會直接把 `MEMORY.md` 內容（最高取到 4000 字）無條件當成系統提示詞的前綴「以下是你的長期記憶，可用於回答問題：」並塞入模型的上下文中。

## 4. 架構圖示

```mermaid
graph TD
    User[User (Telegram/CLI)] --> Adapter[Agent Adapter]
    Adapter --> Session[Session Manager]
    Session <--> HistFile[(history/*.json)]
    
    Adapter --> Agent[AI Agent]
    Agent --> Tools[Tool Registry]
    
    subgraph Memory System
        Tools --> MemSave[memory_save Tool]
        Tools --> MemConfirm[memory_confirm Tool]
        Tools --> MemSearch[memory_search Tool]
        
        MemSave --> Pending[Pending Store (RAM)]
        MemConfirm --> Pending
        MemConfirm --> Controller
        
        Controller --> Manager[Memory Manager]
        Manager <--> VecDB[(pcai_memory.sqlite)]
        Manager <--> Markdown[(MEMORY.md)]
    end
    
    subgraph ShortTerm
        Adapter --> SQLite[(pcai.db)]
    end
```
